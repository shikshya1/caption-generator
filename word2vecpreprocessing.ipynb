{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"word2vecpreprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"KK3WXe2oz8az","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"634b684a-b482-4e8d-b64e-b854d4983336","executionInfo":{"status":"ok","timestamp":1573884291960,"user_tz":-420,"elapsed":23478,"user":{"displayName":"Shikshya Dahal","photoUrl":"","userId":"13672899809593533424"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/ML-Project1/image-generator/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"msrBsuhCyLGR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":188},"outputId":"ededa61e-7c5e-43dd-9a30-df74fe3bfada","executionInfo":{"status":"ok","timestamp":1573885582691,"user_tz":-420,"elapsed":2444,"user":{"displayName":"Shikshya Dahal","photoUrl":"","userId":"13672899809593533424"}}},"source":["# prepare word vectors for captioning model\n"," \n","from numpy import asarray\n","from pickle import dump\n","from gensim.models import Word2Vec\n","from config import config\n"," \n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n"," \n","# load a pre-defined list of photo identifiers\n","def load_set(filename):\n","\tdoc = load_doc(filename)\n","\tdataset = list()\n","\t# process line by line\n","\tfor line in doc.split('\\n'):\n","\t\t# skip empty lines\n","\t\tif len(line) < 1:\n","\t\t\tcontinue\n","\t\t# get the image identifier\n","\t\tidentifier = line.split('.')[0]\n","\t\tdataset.append(identifier)\n","\treturn set(dataset)\n"," \n","\n"," \n","# load clean descriptions into memory\n","def load_clean_descriptions(filename, dataset):\n","\t# load document\n","\tdoc = load_doc(filename)\n","\tdescriptions = dict()\n","\tfor line in doc.split('\\n'):\n","\t\t# split line by white space\n","\t\ttokens = line.split()\n","\t\t# split id from description\n","\t\timage_id, image_desc = tokens[0], tokens[1:]\n","\t\t# skip images not in the set\n","\t\tif image_id in dataset:\n","\t\t\t# store\n","\t\t\tdescriptions[image_id] = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","\treturn descriptions\n"," \n","# load dev set\n","dataset = load_set(config['train_data_path'])\n","print('Dataset: %d' % len(dataset))\n","\n","train_descriptions = load_clean_descriptions('/content/drive/My Drive/ML-Project1/image-generator/descriptions.txt', dataset)\n","print('Descriptions: train=%d' % len(train_descriptions))\n"," \n","# train word2vec model\n","lines = [s.split() for s in train_descriptions.values()]\n","model = Word2Vec(lines, size=100, window=5, workers=8, min_count=1)\n","# summarize vocabulary size in model\n","words = list(model.wv.vocab)\n","print('Vocabulary size: %d' % len(words))\n"," \n","# save model in ASCII (word2vec) format\n","filename ='/content/drive/My Drive/ML-Project1/image-generator/model_data/custom_embedding.txt'\n","model.wv.save_word2vec_format(filename, binary=False)\n"," \n","# load the whole embedding into memory\n","embedding = dict()\n","file = open('/content/drive/My Drive/ML-Project1/image-generator/model_data/custom_embedding.txt')\n","for line in file:\n","\tvalues = line.split()\n","\tword = values[0]\n","\tcoefs = asarray(values[1:], dtype='float32')\n","\tembedding[word] = coefs\n","file.close()\n","print('Embedding Size: %d' % len(embedding))\n"," \n","# summarize vocabulary\n","all_tokens = ' '.join(train_descriptions.values()).split()\n","vocabulary = set(all_tokens)\n","print('Vocabulary Size: %d' % len(vocabulary))\n"," \n","# get the vectors for words in our vocab\n","cust_embedding = dict()\n","for word in vocabulary:\n","\t# check if word in embedding\n","\tif word not in embedding:\n","\t\tcontinue\n","\tcust_embedding[word] = embedding[word]\n","print('Custom Embedding %d' % len(cust_embedding))\n"," \n","# save\n","dump(cust_embedding, open('/content/drive/My Drive/ML-Project1/image-generator/model_data/word2vec_embedding.pkl', 'wb'))\n","print('Saved Embedding')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Dataset: 6000\n","Descriptions: train=6000\n","Vocabulary size: 3837\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["Embedding Size: 3838\n","Vocabulary Size: 3837\n","Custom Embedding 3837\n","Saved Embedding\n"],"name":"stdout"}]}]}